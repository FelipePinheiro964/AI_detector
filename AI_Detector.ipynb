{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fba1cabe",
   "metadata": {},
   "source": [
    "> IMPORTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c2ebb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão do Python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]\n",
      "PyTorch: 2.5.1\n",
      "OpenCV: 4.10.0\n",
      "MediaPipe: 0.10.31\n"
     ]
    }
   ],
   "source": [
    "# Manipulação de Arquivos e Sistema\n",
    "import os\n",
    "import sys\n",
    "from tqdm.notebook import tqdm # Versão especial do tqdm para o Jupyter\n",
    "\n",
    "# Visão Computacional e Imagem\n",
    "import cv2\n",
    "import PIL.Image\n",
    "from PIL import Image\n",
    "\n",
    "# Machine Learning e Deep Learning (PyTorch)\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Biometria e Detecção Facial\n",
    "import mediapipe as mp\n",
    "\n",
    "# Processamento de Dados e Visualização\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Verificação de Versões e Hardware\n",
    "print(f\"Versão do Python: {sys.version}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"OpenCV: {cv2.__version__}\")\n",
    "print(f\"MediaPipe: {mp.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6cb7a5",
   "metadata": {},
   "source": [
    "> YOLO dataset training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c81df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO # Para detectar caminhões, prédios, etc.\n",
    "\n",
    "model_yolo = YOLO('yolov8n.pt') # Modelo leve que identifica 80 tipos de objetos\n",
    "\n",
    "def analisar_contexto(frame):\n",
    "    results = model_yolo(frame)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840120fa",
   "metadata": {},
   "source": [
    "> Teste de video teclado/mouse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb3b8d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 keyboard, 52.2ms\n",
      "Speed: 14.0ms preprocess, 52.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 50.8ms\n",
      "Speed: 2.7ms preprocess, 50.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 44.2ms\n",
      "Speed: 2.4ms preprocess, 44.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 43.1ms\n",
      "Speed: 2.6ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 60.1ms\n",
      "Speed: 2.6ms preprocess, 60.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 44.6ms\n",
      "Speed: 2.9ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 44.1ms\n",
      "Speed: 2.3ms preprocess, 44.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 1 cell phone, 46.0ms\n",
      "Speed: 2.7ms preprocess, 46.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 1 cell phone, 44.4ms\n",
      "Speed: 2.0ms preprocess, 44.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 1 cell phone, 43.3ms\n",
      "Speed: 2.6ms preprocess, 43.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 1 cell phone, 45.3ms\n",
      "Speed: 2.0ms preprocess, 45.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 42.2ms\n",
      "Speed: 2.4ms preprocess, 42.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 41.4ms\n",
      "Speed: 2.4ms preprocess, 41.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 40.4ms\n",
      "Speed: 2.3ms preprocess, 40.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 40.3ms\n",
      "Speed: 1.7ms preprocess, 40.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 38.0ms\n",
      "Speed: 1.8ms preprocess, 38.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 39.9ms\n",
      "Speed: 2.0ms preprocess, 39.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 38.7ms\n",
      "Speed: 2.0ms preprocess, 38.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 41.6ms\n",
      "Speed: 2.7ms preprocess, 41.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 40.0ms\n",
      "Speed: 2.3ms preprocess, 40.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 39.5ms\n",
      "Speed: 2.3ms preprocess, 39.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 40.3ms\n",
      "Speed: 2.0ms preprocess, 40.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 40.8ms\n",
      "Speed: 2.0ms preprocess, 40.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 39.3ms\n",
      "Speed: 1.9ms preprocess, 39.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 44.9ms\n",
      "Speed: 2.9ms preprocess, 44.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 43.4ms\n",
      "Speed: 1.9ms preprocess, 43.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 39.5ms\n",
      "Speed: 2.6ms preprocess, 39.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 39.6ms\n",
      "Speed: 2.2ms preprocess, 39.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 39.0ms\n",
      "Speed: 1.8ms preprocess, 39.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 39.2ms\n",
      "Speed: 2.4ms preprocess, 39.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 38.9ms\n",
      "Speed: 2.3ms preprocess, 38.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 41.6ms\n",
      "Speed: 2.5ms preprocess, 41.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 41.2ms\n",
      "Speed: 2.2ms preprocess, 41.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 43.5ms\n",
      "Speed: 2.8ms preprocess, 43.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 41.7ms\n",
      "Speed: 2.3ms preprocess, 41.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 41.7ms\n",
      "Speed: 2.3ms preprocess, 41.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 39.3ms\n",
      "Speed: 2.3ms preprocess, 39.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 40.4ms\n",
      "Speed: 1.8ms preprocess, 40.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 40.5ms\n",
      "Speed: 2.7ms preprocess, 40.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 42.3ms\n",
      "Speed: 2.4ms preprocess, 42.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 41.0ms\n",
      "Speed: 2.8ms preprocess, 41.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 39.9ms\n",
      "Speed: 2.0ms preprocess, 39.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 39.6ms\n",
      "Speed: 2.4ms preprocess, 39.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 40.9ms\n",
      "Speed: 2.0ms preprocess, 40.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 41.8ms\n",
      "Speed: 2.2ms preprocess, 41.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 41.0ms\n",
      "Speed: 2.2ms preprocess, 41.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 40.8ms\n",
      "Speed: 2.6ms preprocess, 40.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 42.3ms\n",
      "Speed: 2.1ms preprocess, 42.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 43.0ms\n",
      "Speed: 1.8ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 42.1ms\n",
      "Speed: 2.2ms preprocess, 42.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 38.5ms\n",
      "Speed: 1.8ms preprocess, 38.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 40.5ms\n",
      "Speed: 2.1ms preprocess, 40.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 40.6ms\n",
      "Speed: 2.5ms preprocess, 40.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 39.5ms\n",
      "Speed: 2.5ms preprocess, 39.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 40.1ms\n",
      "Speed: 2.0ms preprocess, 40.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 40.0ms\n",
      "Speed: 2.1ms preprocess, 40.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 37.8ms\n",
      "Speed: 2.1ms preprocess, 37.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 40.3ms\n",
      "Speed: 2.1ms preprocess, 40.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 39.8ms\n",
      "Speed: 2.0ms preprocess, 39.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 41.7ms\n",
      "Speed: 2.3ms preprocess, 41.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 40.6ms\n",
      "Speed: 2.0ms preprocess, 40.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 37.3ms\n",
      "Speed: 2.3ms preprocess, 37.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 37.6ms\n",
      "Speed: 2.0ms preprocess, 37.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 keyboard, 40.1ms\n",
      "Speed: 1.9ms preprocess, 40.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 40.9ms\n",
      "Speed: 2.0ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 38.4ms\n",
      "Speed: 1.8ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 38.8ms\n",
      "Speed: 2.0ms preprocess, 38.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 38.4ms\n",
      "Speed: 2.2ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 40.0ms\n",
      "Speed: 2.1ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 39.0ms\n",
      "Speed: 2.1ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 38.1ms\n",
      "Speed: 1.8ms preprocess, 38.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 40.6ms\n",
      "Speed: 2.0ms preprocess, 40.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 39.7ms\n",
      "Speed: 1.8ms preprocess, 39.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 39.8ms\n",
      "Speed: 2.2ms preprocess, 39.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 42.5ms\n",
      "Speed: 2.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 42.1ms\n",
      "Speed: 2.4ms preprocess, 42.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 43.2ms\n",
      "Speed: 2.6ms preprocess, 43.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 41.0ms\n",
      "Speed: 2.0ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 40.6ms\n",
      "Speed: 1.9ms preprocess, 40.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 tv, 42.1ms\n",
      "Speed: 2.0ms preprocess, 42.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 tie, 1 tv, 40.1ms\n",
      "Speed: 1.8ms preprocess, 40.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 tie, 41.9ms\n",
      "Speed: 2.1ms preprocess, 41.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 1 tie, 1 cell phone, 39.5ms\n",
      "Speed: 1.9ms preprocess, 39.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 tie, 42.3ms\n",
      "Speed: 2.3ms preprocess, 42.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 42.3ms\n",
      "Speed: 2.1ms preprocess, 42.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 39.9ms\n",
      "Speed: 2.9ms preprocess, 39.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 40.0ms\n",
      "Speed: 2.3ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 41.7ms\n",
      "Speed: 2.0ms preprocess, 41.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 41.8ms\n",
      "Speed: 1.7ms preprocess, 41.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 39.8ms\n",
      "Speed: 2.1ms preprocess, 39.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 41.0ms\n",
      "Speed: 2.0ms preprocess, 41.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 39.4ms\n",
      "Speed: 2.0ms preprocess, 39.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 41.7ms\n",
      "Speed: 2.1ms preprocess, 41.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 cell phone, 38.7ms\n",
      "Speed: 1.7ms preprocess, 38.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 laptop, 40.7ms\n",
      "Speed: 2.9ms preprocess, 40.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 39.1ms\n",
      "Speed: 1.9ms preprocess, 39.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 37.9ms\n",
      "Speed: 2.3ms preprocess, 37.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 39.6ms\n",
      "Speed: 1.9ms preprocess, 39.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 37.2ms\n",
      "Speed: 1.9ms preprocess, 37.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 35.8ms\n",
      "Speed: 2.2ms preprocess, 35.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 mouse, 38.0ms\n",
      "Speed: 1.9ms preprocess, 38.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 mouse, 37.5ms\n",
      "Speed: 2.7ms preprocess, 37.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 mouse, 37.7ms\n",
      "Speed: 2.1ms preprocess, 37.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 38.4ms\n",
      "Speed: 2.5ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 38.6ms\n",
      "Speed: 1.7ms preprocess, 38.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 39.0ms\n",
      "Speed: 1.9ms preprocess, 39.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 remote, 64.1ms\n",
      "Speed: 2.2ms preprocess, 64.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 39.6ms\n",
      "Speed: 2.2ms preprocess, 39.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 36.6ms\n",
      "Speed: 2.2ms preprocess, 36.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 39.2ms\n",
      "Speed: 2.1ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 36.9ms\n",
      "Speed: 1.9ms preprocess, 36.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 37.5ms\n",
      "Speed: 1.7ms preprocess, 37.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 38.7ms\n",
      "Speed: 2.3ms preprocess, 38.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 remote, 35.8ms\n",
      "Speed: 2.1ms preprocess, 35.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 mouse, 1 remote, 35.8ms\n",
      "Speed: 2.1ms preprocess, 35.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 40.0ms\n",
      "Speed: 2.2ms preprocess, 40.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 remote, 39.1ms\n",
      "Speed: 1.9ms preprocess, 39.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 39.0ms\n",
      "Speed: 2.2ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 38.3ms\n",
      "Speed: 2.1ms preprocess, 38.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 38.0ms\n",
      "Speed: 2.1ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 cup, 40.3ms\n",
      "Speed: 1.6ms preprocess, 40.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 38.1ms\n",
      "Speed: 2.1ms preprocess, 38.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 39.3ms\n",
      "Speed: 2.3ms preprocess, 39.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 mouse, 1 cell phone, 37.8ms\n",
      "Speed: 1.7ms preprocess, 37.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 remote, 39.2ms\n",
      "Speed: 2.2ms preprocess, 39.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 38.6ms\n",
      "Speed: 1.9ms preprocess, 38.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 cell phone, 41.6ms\n",
      "Speed: 1.9ms preprocess, 41.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 38.0ms\n",
      "Speed: 2.0ms preprocess, 38.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 41.9ms\n",
      "Speed: 2.0ms preprocess, 41.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 cell phone, 35.7ms\n",
      "Speed: 1.7ms preprocess, 35.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 41.6ms\n",
      "Speed: 1.8ms preprocess, 41.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 37.7ms\n",
      "Speed: 1.7ms preprocess, 37.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 41.4ms\n",
      "Speed: 2.0ms preprocess, 41.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 cell phone, 38.2ms\n",
      "Speed: 1.8ms preprocess, 38.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 40.2ms\n",
      "Speed: 1.9ms preprocess, 40.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 40.0ms\n",
      "Speed: 1.5ms preprocess, 40.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 39.6ms\n",
      "Speed: 1.7ms preprocess, 39.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 39.2ms\n",
      "Speed: 1.4ms preprocess, 39.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 39.7ms\n",
      "Speed: 2.0ms preprocess, 39.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Carrega o modelo \n",
    "model = YOLO('yolov8n.pt') \n",
    "\n",
    "# Caminho do vídeo\n",
    "# Use o caminho exato que aparece no seu VS Code\n",
    "video_path = 'video_test/teste_perifericos.mp4'\n",
    "\n",
    "# Abre o vídeo\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Erro ao abrir o vídeo! Verifique o caminho.\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    \n",
    "    if success:\n",
    "        # Roda a detecção (stream=True é bom para vídeos longos)\n",
    "        results = model(frame, stream=True)\n",
    "        \n",
    "        for r in results:\n",
    "            # r.plot() cria a imagem com as caixinhas e nomes (mouse, keyboard)\n",
    "            annotated_frame = r.plot() \n",
    "            \n",
    "            # Mostra a janela\n",
    "            cv2.imshow(\"IA Detectando Objetos Reais\", annotated_frame)\n",
    "\n",
    "        # O cv2.waitKey(1) é essencial para a janela não travar\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        # Fim do vídeo\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941c718d",
   "metadata": {},
   "source": [
    "- Com a detecção feita com sucesso, esta na hora de tentar identificar anomalias em videos para detectar se é feito de IA ou não.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b818c67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando análise de 139 frames...\n",
      "Frame 0: Forma instável detectada (keyboard)\n",
      "Frame 1: Forma instável detectada (keyboard)\n",
      "Frame 2: Forma instável detectada (keyboard)\n",
      "Frame 3: Forma instável detectada (keyboard)\n",
      "Frame 6: Forma instável detectada (keyboard)\n",
      "Frame 7: Forma instável detectada (cell phone)\n",
      "Frame 8: Forma instável detectada (cell phone)\n",
      "Frame 9: Forma instável detectada (cell phone)\n",
      "Frame 10: Forma instável detectada (cell phone)\n",
      "Frame 62: Forma instável detectada (keyboard)\n",
      "Frame 63: Forma instável detectada (keyboard)\n",
      "Frame 79: Forma instável detectada (tv)\n",
      "Frame 80: Forma instável detectada (tv)\n",
      "Frame 80: Forma instável detectada (tie)\n",
      "Frame 81: Forma instável detectada (tie)\n",
      "Frame 81: Forma instável detectada (person)\n",
      "Frame 82: Forma instável detectada (cell phone)\n",
      "Frame 82: Forma instável detectada (person)\n",
      "Frame 82: Forma instável detectada (tie)\n",
      "Frame 83: Forma instável detectada (tie)\n",
      "Frame 93: Forma instável detectada (cell phone)\n",
      "Frame 94: Forma instável detectada (laptop)\n",
      "Frame 100: Forma instável detectada (mouse)\n",
      "Frame 101: Forma instável detectada (mouse)\n",
      "Frame 102: Forma instável detectada (mouse)\n",
      "Frame 106: Forma instável detectada (remote)\n",
      "Frame 113: Forma instável detectada (remote)\n",
      "Frame 114: Forma instável detectada (remote)\n",
      "Frame 114: Forma instável detectada (mouse)\n",
      "Frame 116: Forma instável detectada (remote)\n",
      "Frame 120: Forma instável detectada (cup)\n",
      "Frame 123: Forma instável detectada (cell phone)\n",
      "Frame 123: Forma instável detectada (mouse)\n",
      "Frame 124: Forma instável detectada (remote)\n",
      "Frame 126: Forma instável detectada (cell phone)\n",
      "Frame 129: Forma instável detectada (cell phone)\n",
      "Frame 133: Forma instável detectada (cell phone)\n",
      "Fim do vídeo ou erro na leitura.\n",
      "\n",
      "--- RESUMO DA ANALISE ---\n",
      "Foram detectadas 37 inconsistências no vídeo.\n"
     ]
    }
   ],
   "source": [
    "video_path = 'video_test/teste_perifericos.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Pega o total de frames\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_count = 0\n",
    "alertas_encontrados = [] # Lista para guardar as bizarrices detectadas\n",
    "\n",
    "print(f\"Iniciando análise de {total_frames} frames...\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    \n",
    "    if not success:\n",
    "        print(\"Fim do vídeo ou erro na leitura.\")\n",
    "        break\n",
    "\n",
    "    # Roda a detecção\n",
    "    results = model(frame, verbose=False)\n",
    "    annotated_frame = results[0].plot()\n",
    "    \n",
    "    # LÓGICA DE DETECÇÃO DE IA/ANOMALIAS\n",
    "    analise_suspeita = False\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            conf = float(box.conf[0])\n",
    "            nome = model.names[int(box.cls[0])]\n",
    "            \n",
    "            # Se a confiança for baixa (comum em vídeos de IA instáveis)\n",
    "            if conf < 0.80:\n",
    "                analise_suspeita = True\n",
    "                msg = f\"Frame {frame_count}: Forma instável detectada ({nome})\"\n",
    "                if msg not in alertas_encontrados:\n",
    "                    alertas_encontrados.append(msg)\n",
    "                    print(f\"{msg}\")\n",
    "\n",
    "    # Feedback Visual para o usuário\n",
    "    status_cor = (0, 0, 255) if analise_suspeita else (0, 255, 0) # Vermelho se suspeito, Verde se ok\n",
    "    status_txt = \"ANALISE: SUSPEITA\" if analise_suspeita else \"ANALISE: REAL\"\n",
    "    \n",
    "    cv2.putText(annotated_frame, status_txt, (50, 70), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, status_cor, 3)\n",
    "    \n",
    "    # Contador de frames\n",
    "    frame_count += 1\n",
    "    cv2.putText(annotated_frame, f\"Frame: {frame_count}/{total_frames}\", (10, 30), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Analisando Realismo\", annotated_frame)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# LIMPEZA\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "for i in range(10):\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "print(\"\\n--- RESUMO DA ANALISE ---\")\n",
    "if alertas_encontrados:\n",
    "    print(f\"Foram detectadas {len(alertas_encontrados)} inconsistências no vídeo.\")\n",
    "else:\n",
    "    print(\"Nenhuma inconsistência grave detectada. O vídeo parece real.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c628fac",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> teste do detector com video de IA Gemini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "675acbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando análise de 192 frames...\n",
      "Frame 66: Forma instável detectada (keyboard)\n",
      "Frame 69: Forma instável detectada (keyboard)\n",
      "Frame 70: Forma instável detectada (keyboard)\n",
      "Frame 71: Forma instável detectada (keyboard)\n",
      "Frame 72: Forma instável detectada (keyboard)\n",
      "Frame 73: Forma instável detectada (keyboard)\n",
      "Frame 74: Forma instável detectada (keyboard)\n",
      "Frame 75: Forma instável detectada (keyboard)\n",
      "Frame 76: Forma instável detectada (cat)\n",
      "Frame 77: Forma instável detectada (cat)\n",
      "Frame 78: Forma instável detectada (donut)\n",
      "Frame 85: Forma instável detectada (cat)\n",
      "Frame 86: Forma instável detectada (cat)\n",
      "Frame 87: Forma instável detectada (cat)\n",
      "Frame 88: Forma instável detectada (cat)\n",
      "Frame 89: Forma instável detectada (cat)\n",
      "Frame 97: Forma instável detectada (cat)\n",
      "Frame 100: Forma instável detectada (bed)\n",
      "Frame 101: Forma instável detectada (cat)\n",
      "Frame 102: Forma instável detectada (cat)\n",
      "Frame 103: Forma instável detectada (cat)\n",
      "Frame 104: Forma instável detectada (cat)\n",
      "Frame 105: Forma instável detectada (cat)\n",
      "Frame 106: Forma instável detectada (cat)\n",
      "Frame 107: Forma instável detectada (cat)\n",
      "Frame 110: Forma instável detectada (cat)\n",
      "Frame 111: Forma instável detectada (cat)\n",
      "Frame 114: Forma instável detectada (cat)\n",
      "Frame 115: Forma instável detectada (cat)\n",
      "Frame 116: Forma instável detectada (cat)\n",
      "Frame 117: Forma instável detectada (cat)\n",
      "Frame 118: Forma instável detectada (cat)\n",
      "Frame 119: Forma instável detectada (cat)\n",
      "Frame 120: Forma instável detectada (cat)\n",
      "Frame 121: Forma instável detectada (cat)\n",
      "Frame 122: Forma instável detectada (cat)\n",
      "Frame 123: Forma instável detectada (cat)\n",
      "Frame 126: Forma instável detectada (cat)\n",
      "Frame 127: Forma instável detectada (cat)\n",
      "Frame 132: Forma instável detectada (cat)\n",
      "Frame 133: Forma instável detectada (cat)\n",
      "Frame 134: Forma instável detectada (cat)\n",
      "Frame 139: Forma instável detectada (bed)\n",
      "Frame 169: Forma instável detectada (cat)\n",
      "Frame 169: Forma instável detectada (bed)\n",
      "Frame 173: Forma instável detectada (cat)\n",
      "Frame 175: Forma instável detectada (cat)\n",
      "Frame 187: Forma instável detectada (bed)\n",
      "Frame 188: Forma instável detectada (bed)\n",
      "Fim do vídeo ou erro na leitura.\n",
      "\n",
      "--- RESUMO DA ANALISE ---\n",
      "Foram detectadas 49 inconsistências no vídeo.\n"
     ]
    }
   ],
   "source": [
    "video_path = 'video_test/Teclado_Vira_Mouse_Vídeo_Pronto.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Pega o total de frames\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_count = 0\n",
    "alertas_encontrados = [] # Lista para guardar as bizarrices detectadas\n",
    "\n",
    "print(f\"Iniciando análise de {total_frames} frames...\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    \n",
    "    if not success:\n",
    "        print(\"Fim do vídeo ou erro na leitura.\")\n",
    "        break\n",
    "\n",
    "    # Roda a detecção\n",
    "    results = model(frame, verbose=False)\n",
    "    annotated_frame = results[0].plot()\n",
    "    \n",
    "    # LÓGICA DE DETECÇÃO DE IA/ANOMALIAS\n",
    "    analise_suspeita = False\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            conf = float(box.conf[0])\n",
    "            nome = model.names[int(box.cls[0])]\n",
    "            \n",
    "            # Se a confiança for baixa (comum em vídeos de IA instáveis)\n",
    "            if conf < 0.80:\n",
    "                analise_suspeita = True\n",
    "                msg = f\"Frame {frame_count}: Forma instável detectada ({nome})\"\n",
    "                if msg not in alertas_encontrados:\n",
    "                    alertas_encontrados.append(msg)\n",
    "                    print(f\"{msg}\")\n",
    "\n",
    "    # Feedback Visual para o usuário\n",
    "    status_cor = (0, 0, 255) if analise_suspeita else (0, 255, 0) # Vermelho se suspeito, Verde se ok\n",
    "    status_txt = \"ANALISE: SUSPEITA\" if analise_suspeita else \"ANALISE: REAL\"\n",
    "    \n",
    "    cv2.putText(annotated_frame, status_txt, (50, 70), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, status_cor, 3)\n",
    "    \n",
    "    # Contador de frames\n",
    "    frame_count += 1\n",
    "    cv2.putText(annotated_frame, f\"Frame: {frame_count}/{total_frames}\", (10, 30), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Analisando Realismo\", annotated_frame)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# LIMPEZA\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "for i in range(10):\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "print(\"\\n--- RESUMO DA ANALISE ---\")\n",
    "if alertas_encontrados:\n",
    "    print(f\"Foram detectadas {len(alertas_encontrados)} inconsistências no vídeo.\")\n",
    "else:\n",
    "    print(\"Nenhuma inconsistência grave detectada. O vídeo parece real.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb3de56",
   "metadata": {},
   "source": [
    "Decepcionante, mas promissor...\n",
    "\n",
    "Conseguimos identificar em algum momento coisas suspeitas no video, mas isso nao mudou o criterio, preciso de algo mais preciso e analitico sobre os videos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032c2017",
   "metadata": {},
   "source": [
    "-- CODIGO COM MEMORIA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1dc52a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando análise de 192 frames...\n",
      "Frame 34: Forma instável detectada (keyboard)\n",
      "Frame 35: Forma instável detectada (keyboard)\n",
      "Frame 36: Forma instável detectada (keyboard)\n",
      "Frame 37: Forma instável detectada (keyboard)\n",
      "ALERTA: Objeto mudou de keyboard para cat instantaneamente!\n",
      "Frame 38: Forma instável detectada (cat)\n",
      "ALERTA: Objeto mudou de cat para donut instantaneamente!\n",
      "ALERTA: Objeto mudou de donut para cat instantaneamente!\n",
      "Frame 42: Forma instável detectada (cat)\n",
      "Frame 43: Forma instável detectada (cat)\n",
      "Frame 44: Forma instável detectada (cat)\n",
      "Frame 48: Forma instável detectada (cat)\n",
      "ALERTA: Objeto mudou de cat para bed instantaneamente!\n",
      "Frame 50: Forma instável detectada (cat)\n",
      "ALERTA: Objeto mudou de bed para cat instantaneamente!\n",
      "Frame 51: Forma instável detectada (cat)\n",
      "Frame 52: Forma instável detectada (cat)\n",
      "Frame 53: Forma instável detectada (cat)\n",
      "Frame 55: Forma instável detectada (cat)\n",
      "Frame 57: Forma instável detectada (cat)\n",
      "Frame 58: Forma instável detectada (cat)\n",
      "Frame 59: Forma instável detectada (cat)\n",
      "Frame 60: Forma instável detectada (cat)\n",
      "Frame 61: Forma instável detectada (cat)\n",
      "Frame 63: Forma instável detectada (cat)\n",
      "Frame 66: Forma instável detectada (cat)\n",
      "Frame 69: Forma instável detectada (bed)\n",
      "Frame 84: Forma instável detectada (cat)\n",
      "Frame 84: Forma instável detectada (bed)\n",
      "Frame 86: Forma instável detectada (cat)\n",
      "Frame 87: Forma instável detectada (cat)\n",
      "Frame 93: Forma instável detectada (bed)\n",
      "ALERTA: Objeto mudou de cat para bed instantaneamente!\n",
      "ALERTA: Objeto mudou de bed para cat instantaneamente!\n",
      "\n",
      "--- RESUMO DA ANALISE ---\n",
      "Foram detectadas 27 inconsistências no vídeo.\n"
     ]
    }
   ],
   "source": [
    "video_path = 'video_test/Teclado_Vira_Mouse_Vídeo_Pronto.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Pega o total de frames\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_count = 0\n",
    "alertas_encontrados = [] # Lista para guardar as bizarrices detectadas\n",
    "\n",
    "print(f\"Iniciando análise de {total_frames} frames...\")\n",
    "\n",
    "historico_objeto = None\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success: break\n",
    "\n",
    "    results = model(frame, verbose=False)\n",
    "    \n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            nome_atual = model.names[int(box.cls[0])]\n",
    "            \n",
    "            # LOGICA DE MUDANÇA BRUSCA:\n",
    "            if historico_objeto and nome_atual != historico_objeto:\n",
    "                print(f\"ALERTA: Objeto mudou de {historico_objeto} para {nome_atual} instantaneamente!\")\n",
    "                status_txt = \"ANALISE: IA DETECTADA (Transformacao)\"\n",
    "                status_cor = (0, 0, 255)\n",
    "            else:\n",
    "                status_txt = \"ANALISE: REAL\"\n",
    "                status_cor = (0, 255, 0)\n",
    "            \n",
    "            historico_objeto = nome_atual # Salva para o próximo frame\n",
    "            \n",
    "    success, frame = cap.read()\n",
    "    \n",
    "    if not success:\n",
    "        print(\"Fim do vídeo ou erro na leitura.\")\n",
    "        break\n",
    "\n",
    "    # Roda a detecção\n",
    "    results = model(frame, verbose=False)\n",
    "    annotated_frame = results[0].plot()\n",
    "    \n",
    "    # LÓGICA DE DETECÇÃO DE IA/ANOMALIAS\n",
    "    analise_suspeita = False\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            conf = float(box.conf[0])\n",
    "            nome = model.names[int(box.cls[0])]\n",
    "            \n",
    "            # Se a confiança for baixa (comum em vídeos de IA instáveis)\n",
    "            if conf < 0.80:\n",
    "                analise_suspeita = True\n",
    "                msg = f\"Frame {frame_count}: Forma instável detectada ({nome})\"\n",
    "                if msg not in alertas_encontrados:\n",
    "                    alertas_encontrados.append(msg)\n",
    "                    print(f\"{msg}\")\n",
    "\n",
    "    # Feedback Visual para o usuário\n",
    "    status_cor = (0, 0, 255) if analise_suspeita else (0, 255, 0) # Vermelho se suspeito, Verde se ok\n",
    "    status_txt = \"ANALISE: SUSPEITA\" if analise_suspeita else \"ANALISE: REAL\"\n",
    "    \n",
    "    cv2.putText(annotated_frame, status_txt, (50, 70), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, status_cor, 3)\n",
    "    \n",
    "    # Contador de frames\n",
    "    frame_count += 1\n",
    "    cv2.putText(annotated_frame, f\"Frame: {frame_count}/{total_frames}\", (10, 30), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Analisando Realismo\", annotated_frame)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# LIMPEZA\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "for i in range(10):\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "print(\"\\n--- RESUMO DA ANALISE ---\")\n",
    "if alertas_encontrados:\n",
    "    print(f\"Foram detectadas {len(alertas_encontrados)} inconsistências no vídeo.\")\n",
    "else:\n",
    "    print(\"Nenhuma inconsistência grave detectada. O vídeo parece real.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "428df3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoramento em tempo real iniciado... Pressione 'q' para parar.\n",
      "Monitoramento encerrado.\n"
     ]
    }
   ],
   "source": [
    "from mss import mss\n",
    "from plyer import notification\n",
    "import time\n",
    "\n",
    "# Configuração da captura de tela\n",
    "sct = mss()\n",
    "# Define a região da tela\n",
    "monitor = sct.monitors[1] \n",
    "\n",
    "notificacao_enviada = False\n",
    "ultimo_alerta_time = 0\n",
    "tempo_de_espera_alerta = 60 # Espera 60 segundos para avisar de novo (evita spam)\n",
    "\n",
    "print(\"Monitoramento em tempo real iniciado... Pressione 'q' para parar.\")\n",
    "\n",
    "while True:\n",
    "    # Captura o frame da tela\n",
    "    sct_img = sct.grab(monitor)\n",
    "    frame = np.array(sct_img)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR) # Converte para o formato do OpenCV\n",
    "\n",
    "    # IA analisa a imagem da tela\n",
    "    results = model(frame, verbose=False, conf=0.8) # Confiança mínima 0.8\n",
    "    \n",
    "    analise_suspeita = False\n",
    "    motivo = \"\"\n",
    "\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            conf = float(box.conf[0])\n",
    "            nome = model.names[int(box.cls[0])]\n",
    "            \n",
    "            # Lógica de suspeita (confiança baixa ou objetos instáveis)\n",
    "            if conf < 0.55: \n",
    "                analise_suspeita = True\n",
    "                motivo = f\"Detectado objeto instável: {nome}\"\n",
    "                break\n",
    "\n",
    "    # Lógica de Notificação Única\n",
    "    current_time = time.time()\n",
    "    if analise_suspeita and (current_time - ultimo_alerta_time > tempo_de_espera_alerta):\n",
    "        notification.notify(\n",
    "            title='Alerta de Segurança de IA',\n",
    "            message=f'Detectamos uma possível manipulação visual na sua tela: {motivo}',\n",
    "            app_name='Detector Protetor',\n",
    "            timeout=10 # Tempo que a notificação fica na tela\n",
    "        )\n",
    "        print(f\"NOTIFICAÇÃO ENVIADA: {motivo}\")\n",
    "        ultimo_alerta_time = current_time\n",
    "\n",
    "    # Mostra o que a IA está vendo\n",
    "    annotated_frame = results[0].plot()\n",
    "    cv2.imshow(\"Monitor de IA em Tempo Real\", cv2.resize(annotated_frame, (800, 450)))\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Monitoramento encerrado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9d380e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoramento em tempo real iniciado.\n",
      "Notificação enviada para a Central do Windows: Objeto com forma indefinida (cat)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from mss import mss\n",
    "from plyer import notification\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Carrega o modelo (certifique-se de que o model já foi definido antes)\n",
    "model = YOLO('yolov8n.pt') \n",
    "\n",
    "sct = mss()\n",
    "monitor = sct.monitors[1] \n",
    "\n",
    "# Variáveis de controle de notificação\n",
    "ultimo_alerta_time = 0\n",
    "tempo_de_espera_alerta = 60 \n",
    "\n",
    "print(\"Monitoramento em tempo real iniciado.\")\n",
    "\n",
    "while True:\n",
    "    sct_img = sct.grab(monitor)\n",
    "    frame = np.array(sct_img)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "    # IA analisa a tela\n",
    "    results = model(frame, verbose=False, conf=0.6)\n",
    "    \n",
    "    analise_suspeita = False\n",
    "    motivo = \"\"\n",
    "\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            conf = float(box.conf[0])\n",
    "            nome = model.names[int(box.cls[0])]\n",
    "            \n",
    "            # Se a confiança for baixa, marcamos como suspeito\n",
    "            if conf < 0.8: \n",
    "                analise_suspeita = True\n",
    "                motivo = f\"Objeto com forma indefinida ({nome})\"\n",
    "                break\n",
    "\n",
    "    # ENVIO DA NOTIFICAÇÃO NATIVA\n",
    "    current_time = time.time()\n",
    "    if analise_suspeita and (current_time - ultimo_alerta_time > tempo_de_espera_alerta):\n",
    "        try:\n",
    "            notification.notify(\n",
    "                title='Cuidado: Vídeo Suspeito',\n",
    "                message=f'A IA detectou algo estranho na sua tela: {motivo}. Pode ser um vídeo falso.',\n",
    "                app_name='Detector Protetor',\n",
    "                # Você pode colocar um ícone .ico aqui para parecer mais profissional\n",
    "                # ticker='Alerta de Segurança', \n",
    "                timeout=10\n",
    "            )\n",
    "            print(f\"Notificação enviada para a Central do Windows: {motivo}\")\n",
    "            ultimo_alerta_time = current_time\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao enviar notificação: {e}\")\n",
    "\n",
    "    # Visualização (aperte Q para sair)\n",
    "    annotated_frame = results[0].plot()\n",
    "    cv2.imshow(\"Monitor Protetor\", cv2.resize(annotated_frame, (640, 360)))\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detector_ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
